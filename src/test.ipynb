{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import OxfordPetDataset\n",
    "from augmentation import batch\n",
    "from models import clip_segmentation_model # 2_c exercise\n",
    "from experiment import plot_results\n",
    "\n",
    "# Load the data\n",
    "dataset = OxfordPetDataset()\n",
    "dataset.load_data()\n",
    "dataset.one_hot_encoding()\n",
    "\n",
    "# Resize and normalize\n",
    "reshape_size = (256, 256)\n",
    "dataset.res_norm(reshape_size)\n",
    "dataset.mask_prep()\n",
    "\n",
    "train = dataset.train_raw\n",
    "val = dataset.val_raw\n",
    "test = dataset.test_raw\n",
    "ds_info = dataset.ds_info\n",
    "get_label_name = dataset.get_label_name\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for i, example in enumerate(train.take(2)):  # Take two examples\n",
    "    print(f\"Example {i+1} - Image shape:\", example['image'].shape)\n",
    "    image = example['image']\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(image)\n",
    "    label = example['label']\n",
    "    print(f\"Example {i+1} - Label = \", label.numpy())\n",
    "    mask = example['segmentation_mask']  # This is the segmentation mask\n",
    "    plt.imshow(mask, cmap='gray', alpha=0.5)\n",
    "    print(f\"Example {i+1} - Mask shape:\", mask.numpy().shape)\n",
    "    print(\"\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_mask(data):\n",
    "    \"\"\"Extract image and mask from dictionary\"\"\"\n",
    "    return data['image'], data['segmentation_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidia\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:327: UserWarning: models is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 37\n",
      "Number of training samples: 3312\n",
      "Number of validation samples: 368\n",
      "Number of test samples: 3669\n",
      "115/115 [==============================] - 54s 431ms/step - loss: 0.1709 - accuracy: 0.9294 - mean_io_u_wrapper_14: 0.8296 - dice_coefficient: 0.9044\n",
      "Iteration 0.0: {'loss': 0.17088498175144196, 'accuracy': 0.9293954968452454, 'mean_io_u_wrapper_14': 0.8296310305595398, 'dice_coefficient': 0.9043943285942078}\n",
      "Test metrics for iteration 0.0 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 51s 433ms/step - loss: 0.2080 - accuracy: 0.9180 - mean_io_u_wrapper_14: 0.7959 - dice_coefficient: 0.8835\n",
      "Iteration 0.02: {'loss': 0.20800556242465973, 'accuracy': 0.9179819226264954, 'mean_io_u_wrapper_14': 0.7958829402923584, 'dice_coefficient': 0.8835465908050537}\n",
      "Test metrics for iteration 0.02 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 52s 446ms/step - loss: 0.2278 - accuracy: 0.9123 - mean_io_u_wrapper_14: 0.7800 - dice_coefficient: 0.8733\n",
      "Iteration 0.04: {'loss': 0.22777831554412842, 'accuracy': 0.9123323559761047, 'mean_io_u_wrapper_14': 0.7799797058105469, 'dice_coefficient': 0.8732988238334656}\n",
      "Test metrics for iteration 0.04 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 53s 453ms/step - loss: 0.2576 - accuracy: 0.9047 - mean_io_u_wrapper_14: 0.7595 - dice_coefficient: 0.8589\n",
      "Iteration 0.06: {'loss': 0.2575874924659729, 'accuracy': 0.9047031998634338, 'mean_io_u_wrapper_14': 0.7594830393791199, 'dice_coefficient': 0.8589388132095337}\n",
      "Test metrics for iteration 0.06 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 55s 472ms/step - loss: 0.2863 - accuracy: 0.8970 - mean_io_u_wrapper_14: 0.7380 - dice_coefficient: 0.8436\n",
      "Iteration 0.08: {'loss': 0.2863040566444397, 'accuracy': 0.8970075845718384, 'mean_io_u_wrapper_14': 0.7380253672599792, 'dice_coefficient': 0.8436226844787598}\n",
      "Test metrics for iteration 0.08 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 56s 477ms/step - loss: 0.3324 - accuracy: 0.8863 - mean_io_u_wrapper_14: 0.7099 - dice_coefficient: 0.8240\n",
      "Iteration 0.1: {'loss': 0.3323897123336792, 'accuracy': 0.8863360285758972, 'mean_io_u_wrapper_14': 0.7098576426506042, 'dice_coefficient': 0.8239525556564331}\n",
      "Test metrics for iteration 0.1 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 57s 483ms/step - loss: 0.3777 - accuracy: 0.8757 - mean_io_u_wrapper_14: 0.6821 - dice_coefficient: 0.8032\n",
      "Iteration 0.12: {'loss': 0.37765413522720337, 'accuracy': 0.8757303357124329, 'mean_io_u_wrapper_14': 0.6820797920227051, 'dice_coefficient': 0.8031907677650452}\n",
      "Test metrics for iteration 0.12 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 61s 522ms/step - loss: 0.4359 - accuracy: 0.8652 - mean_io_u_wrapper_14: 0.6544 - dice_coefficient: 0.7802\n",
      "Iteration 0.14: {'loss': 0.4358689486980438, 'accuracy': 0.8651741147041321, 'mean_io_u_wrapper_14': 0.6543640494346619, 'dice_coefficient': 0.7801826000213623}\n",
      "Test metrics for iteration 0.14 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 58s 492ms/step - loss: 0.4868 - accuracy: 0.8543 - mean_io_u_wrapper_14: 0.6260 - dice_coefficient: 0.7575\n",
      "Iteration 0.16: {'loss': 0.48680949211120605, 'accuracy': 0.8542624711990356, 'mean_io_u_wrapper_14': 0.6260241866111755, 'dice_coefficient': 0.7574540376663208}\n",
      "Test metrics for iteration 0.16 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n",
      "115/115 [==============================] - 58s 493ms/step - loss: 0.5578 - accuracy: 0.8431 - mean_io_u_wrapper_14: 0.5970 - dice_coefficient: 0.7332\n",
      "Iteration 0.18: {'loss': 0.5578211545944214, 'accuracy': 0.8430505990982056, 'mean_io_u_wrapper_14': 0.5969650745391846, 'dice_coefficient': 0.7331749200820923}\n",
      "Test metrics for iteration 0.18 appended to test_results/Image_Salt_and_Pepper_Noise\\test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "from metrics import MeanIoUWrapper, dice_coefficient\n",
    "import tensorflow as tf\n",
    "from data_loading import OxfordPetDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from augmentation import batch\n",
    "\n",
    "# Load the model\n",
    "top_dir = \"task_2c/baseline\"\n",
    "best_model_folder = os.path.join(top_dir, \"Clip_model\")\n",
    "best_model = tf.keras.models.load_model(best_model_folder, compile=False)\n",
    "best_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', MeanIoUWrapper(num_classes=3), dice_coefficient]\n",
    ")\n",
    "\n",
    "# Define results folder\n",
    "results_folder = \"test_results/Image_Salt_and_Pepper_Noise\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "test_csv_path = os.path.join(results_folder, \"test_metrics.csv\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# Load the data\n",
    "dataset = OxfordPetDataset()\n",
    "dataset.load_data()\n",
    "reshape_size = (256, 256)\n",
    "dataset.res_norm(reshape_size)\n",
    "dataset.mask_prep()\n",
    "\n",
    "# List of perturbation levels\n",
    "# num_times = [1, 2, 3, 4, 5, 6, 7, 8, 9] -> Gaussian Blurring\n",
    "# std = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] \n",
    "# brightness_up = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "# brightness_down = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "# contrast_up = [1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.1, 1.15, 1.20, 1.25]\n",
    "# contrast_down = [1.0, 0.95, 0.90, 0.85, 0.80, 0.60, 0.40, 0.30, 0.20, 0.10]\n",
    "# occlusion_up = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "gaussian_noise_impact = [0.00, 0.02, 0.04, 0.06, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18]\n",
    "# Check if the CSV file exists to add headers only once\n",
    "file_exists = os.path.isfile(test_csv_path)\n",
    "\n",
    "for i in gaussian_noise_impact:\n",
    "    # Apply perturbation (Gaussian pixel noise in this case)\n",
    "    # dataset.first_perturb(std=i) \n",
    "    # Apply perturbation (Gaussian blurring in this case)\n",
    "    # dataset.second_perturb(n=i)\n",
    "    # Apply perturbation (mage contrast increase/decrease in this case)\n",
    "    # dataset.third_perturb(a=i) \n",
    "    # Apply perturbation (Image brightness  in this case)\n",
    "    # dataset.fourth_perturb(b=-i) \n",
    "    # Apply perturbation (Occlusion of Image increase  in this case)\n",
    "    # dataset.fifth_perturb(p=i)\n",
    "    # Apply perturbation (Salt and pepper noise  in this case)\n",
    "    dataset.sixth_perturb(d=i) \n",
    "\n",
    "    # Prepare test dataset\n",
    "    test = dataset.test_perturbed.map(extract_image_mask)\n",
    "    test_ds = batch(test, augment='none', batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Evaluate the model on the perturbed dataset\n",
    "    test_metrics = best_model.evaluate(test_ds, return_dict=True)\n",
    "    print(f\"Iteration {i}: {test_metrics}\")\n",
    "    iou_key = [key for key in test_metrics.keys() if key.startswith(\"mean_io_u_wrapper\")][0]\n",
    "    # Extract metrics\n",
    "    test_results = {\n",
    "        \"Perturbation Level\": [i],\n",
    "        \"Loss\": [test_metrics['loss']],\n",
    "        \"Accuracy\": [test_metrics['accuracy']],\n",
    "        \"IoU\": [test_metrics[iou_key]],\n",
    "        \"Dice Coefficient\": [test_metrics['dice_coefficient']]\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "    # Append results to CSV file\n",
    "    test_results_df.to_csv(test_csv_path, mode='a', index=False, header=not file_exists)\n",
    "\n",
    "    # After the first write, set file_exists to True so headers aren't repeated\n",
    "    file_exists = True\n",
    "\n",
    "    print(f\"Test metrics for iteration {i} appended to {test_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
