{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 37\n",
      "Number of training samples: 3312\n",
      "Number of validation samples: 368\n",
      "Number of test samples: 3669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_loading import OxfordPetDataset\n",
    "from augmentation import random_flip, augmentation_layers_geometric, augmentation_layers_color\n",
    "from models import clip_segmentation_model # 2_c exercise\n",
    "from experiment import plot_results\n",
    "\n",
    "# Load the data\n",
    "dataset = OxfordPetDataset()\n",
    "dataset.load_data()\n",
    "dataset.one_hot_encoding()\n",
    "\n",
    "# Resize and normalize\n",
    "reshape_size = (256, 256)\n",
    "dataset.res_norm(reshape_size)\n",
    "\n",
    "train = dataset.train_raw\n",
    "val = dataset.val_raw\n",
    "test = dataset.test_raw\n",
    "ds_info = dataset.ds_info\n",
    "get_label_name = dataset.get_label_name\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# for i, example in enumerate(train.take(2)):  # Take two examples\n",
    "#     print(f\"Example {i+1} - Image shape:\", example['image'].shape)\n",
    "#     image = example['image']\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.subplot(1, 2, i+1)\n",
    "#     plt.imshow(image)\n",
    "#     label = example['label']\n",
    "#     print(f\"Example {i+1} - Label = \", label.numpy())\n",
    "#     mask = example['segmentation_mask']  # This is the segmentation mask\n",
    "#     plt.imshow(mask, cmap='gray', alpha=0.5)\n",
    "#     print(f\"Example {i+1} - Mask shape:\", mask.numpy().shape)\n",
    "#     print(\"\\n\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_mask(data):\n",
    "    \"\"\"Extract image and mask from dictionary\"\"\"\n",
    "    return data['image'], data['segmentation_mask']\n",
    "\n",
    "# Apply to all datasets\n",
    "train = train.map(extract_image_mask)\n",
    "val = val.map(extract_image_mask)\n",
    "test = test.map(extract_image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_mask(image, mask):\n",
    "    # Add a batch dimension to the image and mask for the augmentation layers\n",
    "    batched_image = tf.expand_dims(image, axis=0)\n",
    "    batched_mask = tf.expand_dims(mask, axis=0)\n",
    "    \n",
    "    # Cast the mask to float32 to match the image's data type after augmentation\n",
    "    batched_mask = tf.cast(batched_mask, tf.float32)\n",
    "    \n",
    "    # Apply color-based augmentations to the image only\n",
    "    aug_image = augmentation_color(batched_image, training=True)\n",
    "    \n",
    "    # Concatenate the augmented image and mask to apply geometric augmentations\n",
    "    combined = tf.concat([aug_image, batched_mask], axis=-1)\n",
    "    \n",
    "    # Apply geometric augmentations to both image and mask\n",
    "    combined = augmentation_geometric(combined, training=True)\n",
    "    \n",
    "    # Split the concatenated tensor back into image and mask\n",
    "    aug_image, aug_mask = tf.split(combined, [3, tf.shape(batched_mask)[-1]], axis=-1)\n",
    "    \n",
    "    # Remove the batch dimension and cast the mask back to uint8 if necessary\n",
    "    aug_image = tf.squeeze(aug_image, axis=0)\n",
    "    aug_mask = tf.squeeze(aug_mask, axis=0)\n",
    "    aug_mask = tf.cast(aug_mask, tf.uint8)  # Cast back to original type if needed\n",
    "    \n",
    "    return aug_image, aug_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Assume `raw_train` is your unaugmented dataset\n",
    "cached_train = train.cache()  # Cache the raw images & masks\n",
    "\n",
    "# Batch the data and use prefetching to optimize loading speed\n",
    "# Apply augmentation dynamically during training, only on the training dataset\n",
    "# train_ds = cached_train.map(\n",
    "#     augment_image_mask, \n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# ).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "train_ds = train.batch(batch_size=BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val.batch(batch_size=BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test.batch(batch_size=BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and compile model\n",
    "from metrics import MeanIoUWrapper,dice_coefficient\n",
    "from models import clip_segmentation_model\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "\n",
    "model = clip_segmentation_model(input_shape=reshape_size + (3,))\n",
    "miou_metric = MeanIoUWrapper(num_classes=3)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy',miou_metric, dice_coefficient])\n",
    "top_dir = \"task_2c/baseline\"\n",
    "best_model_folder = os.path.join(top_dir, \"Clip_model\")\n",
    "# Define callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_folder,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8169 - mean_iou: 0.5470 - dice_coefficient: 0.8171   \n",
      "Epoch 1: val_loss improved from inf to 0.33330, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 91s 593ms/step - loss: 0.4458 - accuracy: 0.8169 - mean_iou: 0.5470 - dice_coefficient: 0.8171 - val_loss: 0.3333 - val_accuracy: 0.8574 - val_mean_iou: 0.5832 - val_dice_coefficient: 0.8562\n",
      "Epoch 2/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8606 - mean_iou: 0.6232 - dice_coefficient: 0.8607  \n",
      "Epoch 2: val_loss improved from 0.33330 to 0.32184, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 54s 518ms/step - loss: 0.3301 - accuracy: 0.8606 - mean_iou: 0.6232 - dice_coefficient: 0.8607 - val_loss: 0.3218 - val_accuracy: 0.8634 - val_mean_iou: 0.6090 - val_dice_coefficient: 0.8625\n",
      "Epoch 3/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.8698 - mean_iou: 0.6455 - dice_coefficient: 0.8698 \n",
      "Epoch 3: val_loss improved from 0.32184 to 0.29928, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 57s 554ms/step - loss: 0.3073 - accuracy: 0.8698 - mean_iou: 0.6455 - dice_coefficient: 0.8698 - val_loss: 0.2993 - val_accuracy: 0.8723 - val_mean_iou: 0.6412 - val_dice_coefficient: 0.8715\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 75ms/step - loss: 0.2993 - accuracy: 0.8723 - mean_iou: 0.6412 - dice_coefficient: 0.8715\n",
      "115/115 [==============================] - 9s 80ms/step - loss: 0.3215 - accuracy: 0.8647 - mean_iou: 0.6367 - dice_coefficient: 0.8647\n",
      "{'loss': 0.3214944005012512, 'accuracy': 0.8647025227546692, 'mean_iou': 0.6367175579071045, 'dice_coefficient': 0.864684522151947}\n",
      "Test metrics saved to task_2c/baseline\\Clip_model_results\\test_metrics.csv\n",
      "Loss plot saved to task_2c/baseline\\Clip_model_results\\loss_plot.png\n",
      "Accuracy plot saved to task_2c/baseline\\Clip_model_results\\accuracy_plot.png\n",
      "IoU plot saved to task_2c/baseline\\Clip_model_results\\iou_plot.png\n",
      "Dice Coefficient plot saved to task_2c/baseline\\Clip_model_results\\dice_plot.png\n",
      "Training history saved to task_2c/baseline\\Clip_model_results\\training_history.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define folder paths\n",
    "top_dir = \"task_2c/baseline\"\n",
    "best_model_folder = os.path.join(top_dir, \"Clip_model\")\n",
    "results_folder = os.path.join(top_dir, \"Clip_model_results\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Load the model without compiling to avoid custom object restoration issues.\n",
    "best_model = tf.keras.models.load_model(best_model_folder, compile=False)\n",
    "\n",
    "# Re-compile the model with the custom metrics.\n",
    "best_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', MeanIoUWrapper(num_classes=3), dice_coefficient]\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_metrics = best_model.evaluate(val_ds, return_dict=True)\n",
    "val_loss = val_metrics['loss']\n",
    "val_accuracy = val_metrics['accuracy']\n",
    "val_iou = val_metrics['mean_iou']\n",
    "val_dice = val_metrics['dice_coefficient']\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = best_model.evaluate(test_ds, return_dict=True)\n",
    "print(test_metrics)\n",
    "test_loss = test_metrics['loss']\n",
    "test_accuracy = test_metrics['accuracy']\n",
    "test_iou = test_metrics['mean_iou']\n",
    "test_dice = test_metrics['dice_coefficient']\n",
    "\n",
    "\n",
    "# Save test results in a separate CSV file\n",
    "test_results = {\n",
    "    \"Loss\": [test_loss],\n",
    "    \"Accuracy\": [test_accuracy],\n",
    "    \"IoU\": [test_iou],\n",
    "    \"Dice Coefficient\": [test_dice]\n",
    "}\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_csv_path = os.path.join(results_folder, \"test_metrics.csv\")\n",
    "test_results_df.to_csv(test_csv_path, index=False)\n",
    "print(f\"Test metrics saved to {test_csv_path}\")\n",
    "\n",
    "# Plot training curves and save training history if available.\n",
    "# 'history' is assumed to be a variable obtained from model.fit() during training.\n",
    "if 'history' in globals():\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    loss_plot_path = os.path.join(results_folder, \"loss_plot.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Loss plot saved to {loss_plot_path}\")\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    accuracy_plot_path = os.path.join(results_folder, \"accuracy_plot.png\")\n",
    "    plt.savefig(accuracy_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Accuracy plot saved to {accuracy_plot_path}\")\n",
    "\n",
    "    # Plot training and validation IoU\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['mean_iou'], label='Training IoU')\n",
    "    plt.plot(history.history['val_mean_iou'], label='Validation IoU')\n",
    "    plt.title('Training and Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    iou_plot_path = os.path.join(results_folder, \"iou_plot.png\")\n",
    "    plt.savefig(iou_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"IoU plot saved to {iou_plot_path}\")\n",
    "\n",
    "    # Plot training and validation Dice Coefficient\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['dice_coefficient'], label='Training Dice Coefficient')\n",
    "    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coefficient')\n",
    "    plt.title('Training and Validation Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice Coefficient')\n",
    "    plt.legend()\n",
    "    dice_plot_path = os.path.join(results_folder, \"dice_plot.png\")\n",
    "    plt.savefig(dice_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Dice Coefficient plot saved to {dice_plot_path}\")\n",
    "\n",
    "    # Save the training history to a CSV file\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_csv_path = os.path.join(results_folder, \"training_history.csv\")\n",
    "    history_df.to_csv(history_csv_path, index=False)\n",
    "    print(f\"Training history saved to {history_csv_path}\")\n",
    "else:\n",
    "    print(\"Training history is not available as 'history' variable.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
