{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 14:44:57.302700: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-03 14:44:57.303847: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 14:44:57.307395: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 14:44:57.316695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741013097.332357   10765 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741013097.336555   10765 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-03 14:44:57.352163: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 14:44:59.270777: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 37\n",
      "Number of training samples: 3312\n",
      "Number of validation samples: 368\n",
      "Number of test samples: 3669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_loading import OxfordPetDataset\n",
    "from augmentation import batch\n",
    "from models import clip_segmentation_model # 2_c exercise\n",
    "from experiment import plot_results\n",
    "\n",
    "# Load the data\n",
    "dataset = OxfordPetDataset()\n",
    "dataset.load_data()\n",
    "dataset.one_hot_encoding()\n",
    "\n",
    "# Resize and normalize\n",
    "reshape_size = (256, 256)\n",
    "dataset.res_norm(reshape_size)\n",
    "dataset.mask_prep()\n",
    "\n",
    "train = dataset.train_raw\n",
    "val = dataset.val_raw\n",
    "test = dataset.test_raw\n",
    "ds_info = dataset.ds_info\n",
    "get_label_name = dataset.get_label_name\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# for i, example in enumerate(train.take(2)):  # Take two examples\n",
    "#     print(f\"Example {i+1} - Image shape:\", example['image'].shape)\n",
    "#     image = example['image']\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.subplot(1, 2, i+1)\n",
    "#     plt.imshow(image)\n",
    "#     label = example['label']\n",
    "#     print(f\"Example {i+1} - Label = \", label.numpy())\n",
    "#     mask = example['segmentation_mask']  # This is the segmentation mask\n",
    "#     plt.imshow(mask, cmap='gray', alpha=0.5)\n",
    "#     print(f\"Example {i+1} - Mask shape:\", mask.numpy().shape)\n",
    "#     print(\"\\n\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_mask(data):\n",
    "    \"\"\"Extract image and mask from dictionary\"\"\"\n",
    "    return data['image'], data['segmentation_mask']\n",
    "\n",
    "# Apply to all datasets\n",
    "train = train.map(extract_image_mask)\n",
    "val = val.map(extract_image_mask)\n",
    "test = test.map(extract_image_mask)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Batch the data and use prefetching to optimize loading speed\n",
    "# Apply augmentation dynamically during training. Augment argument instructions: \n",
    "# none = no augmentation, geometric = [geometric], color = [color], \n",
    "# color+geometric = [color, geometric], color+geometric+noise_filter = [color, geometric, noise_filter]\n",
    "train_ds = batch(train, augment='color+geometric+noise_filter', batch_size=BATCH_SIZE)\n",
    "val_ds = batch(val, augment='none', batch_size=BATCH_SIZE)\n",
    "test_ds = batch(test, augment='none', batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9398ba41949f46dab7cf7b46aa09c7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:  12%|#2        | 73.4M/606M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize and compile model\n",
    "from metrics import MeanIoUWrapper,dice_coefficient\n",
    "from models import clip_segmentation_model\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "\n",
    "model = clip_segmentation_model(input_shape=reshape_size + (3,))\n",
    "miou_metric = MeanIoUWrapper(num_classes=3)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy',miou_metric, dice_coefficient])\n",
    "top_dir = \"task_2c/baseline\"\n",
    "best_model_folder = os.path.join(top_dir, \"Clip_model\")\n",
    "# Define callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_folder,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.8169 - mean_iou: 0.5470 - dice_coefficient: 0.8171   \n",
      "Epoch 1: val_loss improved from inf to 0.33330, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 91s 593ms/step - loss: 0.4458 - accuracy: 0.8169 - mean_iou: 0.5470 - dice_coefficient: 0.8171 - val_loss: 0.3333 - val_accuracy: 0.8574 - val_mean_iou: 0.5832 - val_dice_coefficient: 0.8562\n",
      "Epoch 2/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8606 - mean_iou: 0.6232 - dice_coefficient: 0.8607  \n",
      "Epoch 2: val_loss improved from 0.33330 to 0.32184, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 54s 518ms/step - loss: 0.3301 - accuracy: 0.8606 - mean_iou: 0.6232 - dice_coefficient: 0.8607 - val_loss: 0.3218 - val_accuracy: 0.8634 - val_mean_iou: 0.6090 - val_dice_coefficient: 0.8625\n",
      "Epoch 3/3\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.8698 - mean_iou: 0.6455 - dice_coefficient: 0.8698 \n",
      "Epoch 3: val_loss improved from 0.32184 to 0.29928, saving model to task_2c/baseline\\Clip_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 307). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: task_2c/baseline\\Clip_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 57s 554ms/step - loss: 0.3073 - accuracy: 0.8698 - mean_iou: 0.6455 - dice_coefficient: 0.8698 - val_loss: 0.2993 - val_accuracy: 0.8723 - val_mean_iou: 0.6412 - val_dice_coefficient: 0.8715\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 75ms/step - loss: 0.2993 - accuracy: 0.8723 - mean_iou: 0.6412 - dice_coefficient: 0.8715\n",
      "115/115 [==============================] - 9s 80ms/step - loss: 0.3215 - accuracy: 0.8647 - mean_iou: 0.6367 - dice_coefficient: 0.8647\n",
      "{'loss': 0.3214944005012512, 'accuracy': 0.8647025227546692, 'mean_iou': 0.6367175579071045, 'dice_coefficient': 0.864684522151947}\n",
      "Test metrics saved to task_2c/baseline\\Clip_model_results\\test_metrics.csv\n",
      "Loss plot saved to task_2c/baseline\\Clip_model_results\\loss_plot.png\n",
      "Accuracy plot saved to task_2c/baseline\\Clip_model_results\\accuracy_plot.png\n",
      "IoU plot saved to task_2c/baseline\\Clip_model_results\\iou_plot.png\n",
      "Dice Coefficient plot saved to task_2c/baseline\\Clip_model_results\\dice_plot.png\n",
      "Training history saved to task_2c/baseline\\Clip_model_results\\training_history.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define folder paths\n",
    "top_dir = \"task_2c/baseline\"\n",
    "best_model_folder = os.path.join(top_dir, \"Clip_model\")\n",
    "results_folder = os.path.join(top_dir, \"Clip_model_results\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Load the model without compiling to avoid custom object restoration issues.\n",
    "best_model = tf.keras.models.load_model(best_model_folder, compile=False)\n",
    "\n",
    "# Re-compile the model with the custom metrics.\n",
    "best_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', MeanIoUWrapper(num_classes=3), dice_coefficient]\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_metrics = best_model.evaluate(val_ds, return_dict=True)\n",
    "val_loss = val_metrics['loss']\n",
    "val_accuracy = val_metrics['accuracy']\n",
    "val_iou = val_metrics['mean_iou']\n",
    "val_dice = val_metrics['dice_coefficient']\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = best_model.evaluate(test_ds, return_dict=True)\n",
    "print(test_metrics)\n",
    "test_loss = test_metrics['loss']\n",
    "test_accuracy = test_metrics['accuracy']\n",
    "test_iou = test_metrics['mean_iou']\n",
    "test_dice = test_metrics['dice_coefficient']\n",
    "\n",
    "\n",
    "# Save test results in a separate CSV file\n",
    "test_results = {\n",
    "    \"Loss\": [test_loss],\n",
    "    \"Accuracy\": [test_accuracy],\n",
    "    \"IoU\": [test_iou],\n",
    "    \"Dice Coefficient\": [test_dice]\n",
    "}\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_csv_path = os.path.join(results_folder, \"test_metrics.csv\")\n",
    "test_results_df.to_csv(test_csv_path, index=False)\n",
    "print(f\"Test metrics saved to {test_csv_path}\")\n",
    "\n",
    "# Plot training curves and save training history if available.\n",
    "# 'history' is assumed to be a variable obtained from model.fit() during training.\n",
    "if 'history' in globals():\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    loss_plot_path = os.path.join(results_folder, \"loss_plot.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Loss plot saved to {loss_plot_path}\")\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    accuracy_plot_path = os.path.join(results_folder, \"accuracy_plot.png\")\n",
    "    plt.savefig(accuracy_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Accuracy plot saved to {accuracy_plot_path}\")\n",
    "\n",
    "    # Plot training and validation IoU\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['mean_iou'], label='Training IoU')\n",
    "    plt.plot(history.history['val_mean_iou'], label='Validation IoU')\n",
    "    plt.title('Training and Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    iou_plot_path = os.path.join(results_folder, \"iou_plot.png\")\n",
    "    plt.savefig(iou_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"IoU plot saved to {iou_plot_path}\")\n",
    "\n",
    "    # Plot training and validation Dice Coefficient\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['dice_coefficient'], label='Training Dice Coefficient')\n",
    "    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coefficient')\n",
    "    plt.title('Training and Validation Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice Coefficient')\n",
    "    plt.legend()\n",
    "    dice_plot_path = os.path.join(results_folder, \"dice_plot.png\")\n",
    "    plt.savefig(dice_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Dice Coefficient plot saved to {dice_plot_path}\")\n",
    "\n",
    "    # Save the training history to a CSV file\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    history_csv_path = os.path.join(results_folder, \"training_history.csv\")\n",
    "    history_df.to_csv(history_csv_path, index=False)\n",
    "    print(f\"Training history saved to {history_csv_path}\")\n",
    "else:\n",
    "    print(\"Training history is not available as 'history' variable.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
